{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils: \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# Torch: \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "# NLP: \n",
    "from transformers import BertTokenizer, BertModel\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# Moving model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "import ncs\n",
    "train_call_statements = ncs.load_call_statements('train')\n",
    "test_call_statements = ncs.load_call_statements('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    '''\n",
    "    Inherited class structure from torch.utils.data.Dataset; data structure\n",
    "    '''\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        doc_id, text = self.texts[idx]\n",
    "        return doc_id, text\n",
    "\n",
    "def sliding_window(text, stride, max_len, doc_id):\n",
    "    '''\n",
    "    Inherited; Segment longer `text` into overlapping trunks based on `stride` and `max_len`\n",
    "    '''\n",
    "    tokens = text.lower().split()\n",
    "    stride_len = max_len - stride\n",
    "    windowed_tokens = [tokens[i: i+max_len] for i in range(0, len(tokens), stride_len)]\n",
    "    return [(doc_id, \" \".join(chunk)) for chunk in windowed_tokens]\n",
    "\n",
    "def create_dataset(texts:list, doc_ids:list) -> Dataset:\n",
    "    '''\n",
    "    Inherited; wrapper for `create_dataset`\n",
    "    '''\n",
    "    chunked_texts = []\n",
    "    for text, doc_id in zip(texts, doc_ids):\n",
    "        chunked_texts.extend(sliding_window(text, stride=50, max_len=510, doc_id=doc_id))\n",
    "    dataset = TextDataset(chunked_texts)\n",
    "    return dataset\n",
    "\n",
    "def generate_embeddings(tokenizer, model, dataset, device) -> dict:\n",
    "    '''\n",
    "    Inherited; Generate embedded dataset based on CLS token embedding. Torch based. \n",
    "    '''\n",
    "    # Mapping from doc_id to a list of embeddings\n",
    "    embeddings = defaultdict(list)\n",
    "\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
    "\n",
    "    # Process the data in batches\n",
    "    for doc_ids, texts in tqdm(dataloader):\n",
    "        tokenized_texts = tokenizer(texts, truncation=True, padding='longest', return_tensors='pt')\n",
    "\n",
    "        input_ids = tokenized_texts['input_ids'].to(device)\n",
    "        attention_mask = tokenized_texts['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get the CLS token embeddings\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        # Add the embeddings to our mapping\n",
    "        for doc_id, embedding in zip(doc_ids, cls_embeddings):\n",
    "            embeddings[doc_id].append(embedding.cpu().numpy())  # .item() gets the value of a Tensor with a single value\n",
    "\n",
    "    # Finally, compute the mean embedding for each text\n",
    "    mean_embeddings = {doc_id: np.mean(embeddings[doc_id], axis=0) for doc_id in embeddings}\n",
    "    return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_texts = train_call_statements.text.to_list()\n",
    "train_doc_ids = train_call_statements.statement_uid.to_list()\n",
    "test_texts = test_call_statements.text.to_list()\n",
    "test_doc_ids = test_call_statements.statement_uid.to_list()\n",
    "\n",
    "os.makedirs('features/train', exist_ok=True)\n",
    "os.makedirs('features/test', exist_ok=True)\n",
    "\n",
    "# Encode the training data\n",
    "train_bert_features = pd.DataFrame(\n",
    "    generate_embeddings(tokenizer, model,\n",
    "              create_dataset(train_texts, train_doc_ids),\n",
    "              device)).T\n",
    "train_bert_features.columns = [f'bert{i}' for i in range(len(train_bert_features.columns))]\n",
    "train_bert_features = train_bert_features.reindex(train_doc_ids, fill_value=0)\n",
    "train_bert_features.to_parquet('features/train/bert.parquet')\n",
    "\n",
    "# Encode the testing data\n",
    "test_bert_features = pd.DataFrame(\n",
    "    generate_embeddings(tokenizer, model,\n",
    "              create_dataset(test_texts, test_doc_ids),\n",
    "              device)).T\n",
    "test_bert_features.columns = [f'bert{i}' for i in range(len(test_bert_features.columns))]\n",
    "test_bert_features = test_bert_features.reindex(test_doc_ids, fill_value=0)\n",
    "test_bert_features.to_parquet('features/test/bert.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Role Weights**: These are the weights we assign to the role of the person speaking the statement. The roles can be `CEO`, `CFO`, `Senior Manager`, and `Other`. For instance, if we think that statements made by the CEO carry more weight or are more influential to the call, we can assign a higher weight to the `CEO` role.\n",
    "\n",
    "2. **Section Weights**: These weights are assigned to the different sections of the earnings call. The sections can be `qa` for the Question and Answer section, and `pres` for the Presentation section. If we think that statements made during the Question and Answer section are more revealing and influential, we can assign a higher weight to the `qa` section.\n",
    "\n",
    "3. **Statement Type Weights**: These are the weights we assign to different types of statements. The types can be `A` for answers, `Q` for questions, `O` for operator statements, `P` for presenter remarks, and `U` for unknown statements. For example, if we feel that answers (`A`) and questions (`Q`) carry more information than the other types of statements, we can assign a higher weight to them.\n",
    "\n",
    "4. By manipulating these weights, we can configure our model to focus on the parts of the earnings call that we believe are the most important. Feel free to try out different weight setups and observe how they influence the model's performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Model Configuration { display-mode: \"form\" }\n",
    "model_mapping = dict(\n",
    "    lr='logistic_regression', rf='random_forest', nn='neural_network'\n",
    ")\n",
    "model = 'random_forest' #@param [\"logistic_regression\", \"random_forest\", \"neural_network\"] {type:\"string\"}\n",
    "features = ['bert']\n",
    "holding_period = \"10\" #@param [1, 5, 10] {type:\"string\"}\n",
    "holding_period = int(holding_period)\n",
    "\n",
    "out_folder = '_'.join(features)+f'_{holding_period}days'\n",
    "root_folder = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_weights = {\n",
    "    'CEO': 1.0,\n",
    "    'CFO': 1.0,\n",
    "    'Senior Manager': 0.7,\n",
    "    'Other': 0.5,\n",
    "}\n",
    "section_weights = {\n",
    "    'qa': 1.0,\n",
    "    'pres': 0.5,\n",
    "}\n",
    "statement_type_weights = {\n",
    "    'A': 1.0, 'Q': 1.0,\n",
    "    'O': 0.0, 'P': 1.0,\n",
    "    'U': 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{root_folder}/results/{out_folder}', exist_ok=True)\n",
    "feature_train_files = [f'{root_folder}/features/train/{feature}.parquet' for feature in features]\n",
    "feature_test_files = [f'{root_folder}/features/test/{feature}.parquet' for feature in features]\n",
    "action_file = f'{root_folder}/results/{out_folder}/{model}_actions.csv'\n",
    "model_file = f'{root_folder}/results/{out_folder}/{model}.pkl'\n",
    "\n",
    "ncs.model_train(feature_files=feature_train_files,\n",
    "                classifier=model,\n",
    "                role_weights=role_weights,\n",
    "                section_weights=section_weights,\n",
    "                statement_type_weights=statement_type_weights,\n",
    "                holding_period=holding_period,\n",
    "                save_model=model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncs.model_inference(feature_files=feature_test_files,\n",
    "                    model_file=model_file,\n",
    "                    action_file=action_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate strategies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_file = f'{root_folder}/results/{out_folder}/{model}_portfolio.parquet'\n",
    "\n",
    "ncs.run_strategy(\n",
    "  action_file=action_file,\n",
    "  holding_period=holding_period,\n",
    "  save_portfolio_path=portfolio_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncs.demo_benchmark(strategy='random', holding_period=holding_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncs.report_strategy_analysis(\n",
    "  actions=action_file,\n",
    "  holding_period=holding_period,\n",
    "  portfolio=portfolio_file,\n",
    "  model_name=f'BERT-Embedding {model}'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rncs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
